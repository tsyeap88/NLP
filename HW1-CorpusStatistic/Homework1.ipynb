{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting started to process a text example\n",
    "import nltk\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8239\n",
      "['[', 'poems', 'by', 'william', 'blake', '1789', ']', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence', 'introduction', 'piping', 'down', 'the', 'valleys', 'wild', ',', 'piping', 'songs', 'of', 'pleasant', 'glee', ',', 'on', 'a', 'cloud', 'i', 'saw', 'a', 'child', ',', 'and', 'he', 'laughing', 'said', 'to', 'me', ':', '``', 'pipe', 'a', 'song', 'about', 'a', 'lamb', '!', \"''\", 'so', 'i', 'piped', 'with', 'merry', 'cheer', '.', '``', 'piper', ',', 'pipe', 'that', 'song', 'again', ';', \"''\", 'so', 'i', 'piped', ':', 'he', 'wept', 'to', 'hear', '.', '``', 'drop', 'thy', 'pipe', ',', 'thy', 'happy', 'pipe', ';', 'sing', 'thy', 'songs', 'of', 'happy', 'cheer', ':', '!', \"''\", 'so', 'i', 'sang', 'the', 'same', 'again', ',', 'while', 'he']\n"
     ]
    }
   ],
   "source": [
    "# get the text of the book Emma from the Gutenberg corpus, tokenize it,\n",
    "#   and reduce the tokens to lowercase.\n",
    "file4 = nltk.corpus.gutenberg.fileids( ) [4]\n",
    "poemtext = nltk.corpus.gutenberg.raw(file4)\n",
    "poemtokens = nltk.word_tokenize(poemtext) \n",
    "poemwords = [w.lower( ) for w in poemtokens] \n",
    "# show some of the words\n",
    "print(len(poemwords))\n",
    "print(poemwords[ :110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blake-poems.txt'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'poems', 'by', 'william', 'blake', '1789', ']', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence', 'introduction', 'piping', 'down', 'the', 'valleys', 'wild', ',', 'piping', 'songs', 'of', 'pleasant', 'glee', ',', 'on', 'a', 'cloud', 'i', 'saw', 'a', 'child', ',', 'and', 'he', 'laughing', 'said', 'to', 'me', ':', '``', 'pipe', 'a', 'song', 'about', 'a', 'lamb', '!', \"''\", 'so', 'i', 'piped', 'with', 'merry', 'cheer', '.', '``', 'piper', ',', 'pipe', 'that', 'song', 'again', ';', \"''\", 'so', 'i', 'piped', ':', 'he', 'wept', 'to', 'hear', '.', '``', 'drop', 'thy', 'pipe', ',', 'thy', 'happy', 'pipe', ';', 'sing', 'thy', 'songs', 'of', 'happy', 'cheer', ':', '!']\n",
      "['tell', 'thee', ';', 'little', 'lamb', ',', 'i', \"'ll\", 'tell', 'thee']\n"
     ]
    }
   ],
   "source": [
    "# check tokenization in poemwords\n",
    "print(poemwords[:100])\n",
    "print(poemwords[500:510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist = FreqDist(poemwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 685\n",
      "the \t 439\n",
      "and \t 348\n",
      ". \t 221\n",
      "of \t 146\n",
      "in \t 141\n",
      "i \t 130\n",
      "a \t 127\n",
      "to \t 111\n",
      "; \t 99\n",
      "my \t 83\n",
      ": \t 76\n",
      "! \t 68\n",
      "with \t 66\n",
      "? \t 65\n",
      "his \t 57\n",
      "he \t 56\n",
      "is \t 52\n",
      "`` \t 50\n",
      "'s \t 48\n",
      "little \t 45\n",
      "on \t 44\n",
      "they \t 44\n",
      "not \t 43\n",
      "thee \t 42\n",
      "that \t 39\n",
      "all \t 39\n",
      "but \t 38\n",
      "'' \t 35\n",
      "like \t 35\n",
      "thou \t 35\n",
      "me \t 34\n",
      "their \t 34\n",
      "her \t 34\n",
      "from \t 32\n",
      "for \t 32\n",
      "can \t 32\n",
      "thy \t 31\n",
      "was \t 31\n",
      "then \t 30\n",
      "love \t 29\n",
      "it \t 29\n",
      "sweet \t 28\n",
      "when \t 28\n",
      "night \t 28\n",
      "what \t 26\n",
      "joy \t 25\n",
      "be \t 25\n",
      "are \t 25\n",
      "where \t 25\n"
     ]
    }
   ],
   "source": [
    "# print the top 50 tokens by frequency\n",
    "nitems = ndist.most_common(50)\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'poems', 'by', 'william', 'blake', '1789', ']', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence', 'introduction', 'piping', 'down', 'the', 'valleys', 'wild', ',', 'piping', 'songs', 'of', 'pleasant', 'glee', ',', 'on', 'a', 'cloud', 'i', 'saw', 'a', 'child', ',', 'and', 'he', 'laughing', 'said', 'to', 'me', ':', '``', 'pipe', 'a', 'song', 'about', 'a', 'lamb', '!', \"''\", 'so', 'i', 'piped', 'with', 'merry', 'cheer', '.', '``', 'piper', ',', 'pipe', 'that', 'song', 'again', ';', \"''\", 'so', 'i', 'piped', ':', 'he', 'wept', 'to', 'hear', '.', '``', 'drop', 'thy', 'pipe', ',', 'thy', 'happy', 'pipe', ';', 'sing', 'thy', 'songs', 'of', 'happy', 'cheer', ':', '!', \"''\", 'so', 'i', 'sang', 'the', 'same', 'again', ',', 'while', 'he', 'wept', 'with', 'joy', 'to', 'hear', '.', '``', 'piper', ',', 'sit', 'thee', 'down', 'and', 'write', 'in', 'a', 'book', ',', 'that', 'all', 'may', 'read', '.', \"''\", 'so', 'he', 'vanish', \"'d\", 'from', 'my', 'sight', ';', 'and', 'i', 'pluck', \"'d\", 'a', 'hollow', 'reed', ',', 'and', 'i', 'made', 'a', 'rural', 'pen', ',', 'and', 'i', 'stain']\n",
      "['[', 'poems', 'by', 'william', 'blake', '1789', ']', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence', 'introduction', 'piping', 'down', 'the', 'valleys', 'wild', ',', 'piping', 'songs', 'of', 'pleasant', 'glee', ',', 'on', 'a', 'cloud', 'i', 'saw', 'a', 'child', ',', 'and', 'he', 'laughing', 'said', 'to', 'me', ':', '\"', 'pipe', 'a', 'song', 'about', 'a', 'lamb', '!\"', 'so', 'i', 'piped', 'with', 'merry', 'cheer', '.', '\"', 'piper', ',', 'pipe', 'that', 'song', 'again', ';\"', 'so', 'i', 'piped', ':', 'he', 'wept', 'to', 'hear', '.', '\"', 'drop', 'thy', 'pipe', ',', 'thy', 'happy', 'pipe', ';', 'sing', 'thy', 'songs', 'of', 'happy', 'cheer', ':!\"', 'so', 'i', 'sang', 'the', 'same', 'again', ',', 'while', 'he', 'wept', 'with', 'joy', 'to', 'hear', '.', '\"', 'piper', ',', 'sit', 'thee', 'down', 'and', 'write', 'in', 'a', 'book', ',', 'that', 'all', 'may', 'read', '.\"', 'so', 'he', 'vanish', \"'\", 'd', 'from', 'my', 'sight', ';', 'and', 'i', 'pluck', \"'\", 'd', 'a', 'hollow', 'reed', ',', 'and', 'i', 'made', 'a', 'rural', 'pen', ',', 'and', 'i', 'stain', \"'\", 'd', 'the']\n"
     ]
    }
   ],
   "source": [
    "# look at other tokenization from the corpus\n",
    "poemwords2 = nltk.corpus.gutenberg.words('blake-poems.txt')\n",
    "poemwords2lowercase = [w.lower() for w in poemwords2]\n",
    "print(poemwords[:160])\n",
    "print(poemwords2lowercase[:160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched non-alphabetical\n"
     ]
    }
   ],
   "source": [
    "##  Regular Expression to match non-alphabetic characters\n",
    "import re\n",
    "\n",
    "# this regular expression pattern matches any word that contains all non-alphabetical\n",
    "#   lower-case characters [^a-z]+\n",
    "# the beginning ^ and ending $ require the match to begin and end on a word boundary \n",
    "pattern = re.compile('^[^a-z]+$')\n",
    "\n",
    "nonAlphaMatch = pattern.match('**')\n",
    "#  if it matched, print a message\n",
    "if nonAlphaMatch: print ('matched non-alphabetical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a word and returns true if it consists only\n",
    "#   of non-alphabetic characters  (assumes import re)\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poems', 'by', 'william', 'blake', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence', 'introduction', 'piping', 'down', 'the', 'valleys', 'wild', 'piping', 'songs', 'of', 'pleasant', 'glee', 'on', 'a', 'cloud', 'i', 'saw', 'a', 'child', 'and', 'he', 'laughing', 'said', 'to', 'me', 'pipe', 'a', 'song', 'about', 'a', 'lamb', 'so', 'i', 'piped', 'with', 'merry', 'cheer', 'piper', 'pipe', 'that', 'song', 'again', 'so', 'i', 'piped', 'he', 'wept', 'to', 'hear', 'drop', 'thy', 'pipe', 'thy', 'happy', 'pipe', 'sing', 'thy', 'songs', 'of', 'happy', 'cheer', 'so', 'i', 'sang', 'the', 'same', 'again', 'while', 'he', 'wept', 'with', 'joy', 'to', 'hear', 'piper', 'sit', 'thee', 'down', 'and', 'write', 'in', 'a', 'book']\n",
      "6900\n"
     ]
    }
   ],
   "source": [
    "# apply the function to emmawords\n",
    "alphapoemwords = [w for w in poemwords if not alpha_filter(w)]\n",
    "print(alphapoemwords[:100])\n",
    "print(len(alphapoemwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# get a list of stopwords from nltk\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "print(len(nltkstopwords))\n",
    "print(nltkstopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'poems', 'by', 'william', 'blake', '1789', ']', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence', 'introduction', 'piping', 'down', 'the', 'valleys', 'wild', ',', 'piping', 'songs', 'of', 'pleasant', 'glee', ',', 'on', 'a', 'cloud', 'i', 'saw', 'a', 'child', ',', 'and', 'he', 'laughing', 'said', 'to', 'me', ':', '``', 'pipe', 'a', 'song', 'about', 'a', 'lamb', '!', \"''\", 'so', 'i', 'piped', 'with', 'merry', 'cheer', '.', '``', 'piper', ',', 'pipe', 'that', 'song', 'again', ';', \"''\", 'so', 'i', 'piped', ':', 'he', 'wept', 'to', 'hear', '.', '``', 'drop', 'thy', 'pipe', ',', 'thy', 'happy', 'pipe', ';', 'sing', 'thy', 'songs', 'of', 'happy', 'cheer', ':', '!']\n",
      "['tell', 'thee', ';', 'little', 'lamb', ',', 'i', \"'ll\", 'tell', 'thee', ':', 'he', 'is', 'called', 'by', 'thy', 'name', ',', 'for', 'he', 'calls', 'himself', 'a', 'lamb', 'he', 'is', 'meek', ',', 'and', 'he', 'is', 'mild', ',', 'he', 'became', 'a', 'little', 'child', '.', 'i', 'a', 'child', ',', 'and', 'thou', 'a', 'lamb', ',', 'we', 'are']\n"
     ]
    }
   ],
   "source": [
    "# check tokenization in poemwords\n",
    "print(poemwords[:100])\n",
    "print(poemwords[500:550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'could', 'would', 'might', 'must', 'need', 'sha', 'wo', 'y', \"'s\", \"'d\", \"'ll\", \"'t\", \"'m\", \"'re\", \"'ve\", \"n't\", 'us']\n"
     ]
    }
   ],
   "source": [
    "morestopwords = ['could','would','might','must','need','sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\", \"us\"]\n",
    "\n",
    "stopwords = nltkstopwords + morestopwords\n",
    "print(len(stopwords))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3752\n"
     ]
    }
   ],
   "source": [
    "stoppedpoemwords = [w for w in alphapoemwords if not w in stopwords]\n",
    "print(len(stoppedpoemwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('little', 45)\n",
      "('thee', 42)\n",
      "('like', 35)\n",
      "('thou', 35)\n",
      "('thy', 31)\n",
      "('love', 29)\n",
      "('sweet', 28)\n",
      "('night', 28)\n",
      "('joy', 25)\n",
      "('away', 24)\n",
      "('weep', 24)\n",
      "('father', 22)\n",
      "('sleep', 21)\n",
      "('happy', 19)\n",
      "('shall', 19)\n",
      "('day', 19)\n",
      "('mother', 19)\n",
      "('child', 18)\n",
      "('every', 17)\n",
      "('never', 17)\n",
      "('thel', 16)\n",
      "('hear', 16)\n",
      "('green', 16)\n",
      "('voice', 16)\n",
      "('infant', 16)\n",
      "('see', 16)\n",
      "('human', 16)\n",
      "('cloud', 15)\n",
      "('lamb', 15)\n",
      "('till', 15)\n",
      "('bright', 15)\n",
      "('delight', 14)\n",
      "('upon', 14)\n",
      "('head', 14)\n",
      "('weeping', 14)\n",
      "('holy', 13)\n",
      "('sit', 12)\n",
      "('white', 12)\n",
      "('care', 12)\n",
      "(\"o'er\", 12)\n",
      "('face', 12)\n",
      "('children', 12)\n",
      "('tears', 12)\n",
      "('heard', 12)\n",
      "('sing', 11)\n",
      "('sun', 11)\n",
      "('birds', 11)\n",
      "('god', 11)\n",
      "('boy', 11)\n",
      "('oh', 11)\n"
     ]
    }
   ],
   "source": [
    "# use this list for a better frequency distribution\n",
    "poemdist = FreqDist(stoppedpoemwords)\n",
    "poemitems = poemdist.most_common(50)\n",
    "for item in poemitems:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'poems', 'by', 'william', 'blake', '1789', ']', 'songs', 'of', 'innocence', 'and', 'of', 'experience', 'and', 'the', 'book', 'of', 'thel', 'songs', 'of', 'innocence']\n",
      "[('[', 'poems'), ('poems', 'by'), ('by', 'william'), ('william', 'blake'), ('blake', '1789'), ('1789', ']'), (']', 'songs'), ('songs', 'of'), ('of', 'innocence'), ('innocence', 'and'), ('and', 'of'), ('of', 'experience'), ('experience', 'and'), ('and', 'the'), ('the', 'book'), ('book', 'of'), ('of', 'thel'), ('thel', 'songs'), ('songs', 'of'), ('of', 'innocence')]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "poembigrams = list(nltk.bigrams(poemwords))\n",
    "print(poemwords[:21])\n",
    "print(poembigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "poemfinder = BigramCollocationFinder.from_words(poemwords)\n",
    "poemscored = poemfinder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.020997693894890156)\n",
      "(('in', 'the'), 0.0055832018448840875)\n",
      "(('.', 'the'), 0.0037625925476392767)\n",
      "(('of', 'the'), 0.0033984706881903144)\n",
      "(('and', 'the'), 0.0032770967350406605)\n",
      "((',', 'the'), 0.003155722781891006)\n",
      "(('.', \"''\"), 0.002427479062993082)\n",
      "(('.', 'and'), 0.0023061051098434275)\n",
      "(('and', 'i'), 0.0021847311566937735)\n",
      "(('.', '``'), 0.0020633572035441195)\n",
      "((';', 'and'), 0.0020633572035441195)\n",
      "((',', 'to'), 0.0019419832503944654)\n",
      "((',', 'but'), 0.0016992353440951572)\n",
      "(('on', 'the'), 0.0016992353440951572)\n",
      "(('the', 'little'), 0.0016992353440951572)\n",
      "(('to', 'the'), 0.0016992353440951572)\n",
      "((',', 'i'), 0.001577861390945503)\n",
      "((',', 'in'), 0.001577861390945503)\n",
      "(('in', 'a'), 0.001577861390945503)\n",
      "(('i', 'am'), 0.001456487437795849)\n",
      "(('like', 'a'), 0.001456487437795849)\n",
      "(('the', 'human'), 0.001456487437795849)\n",
      "((',', 'nor'), 0.0013351134846461949)\n",
      "((',', 'who'), 0.0013351134846461949)\n",
      "((',', 'when'), 0.001213739531496541)\n",
      "(('.', 'then'), 0.001213739531496541)\n",
      "(('lamb', ','), 0.001213739531496541)\n",
      "(('love', ','), 0.001213739531496541)\n",
      "(('night', ','), 0.001213739531496541)\n",
      "(('sleep', ','), 0.001213739531496541)\n",
      "(('the', 'night'), 0.001213739531496541)\n",
      "(('!', \"''\"), 0.0010923655783468867)\n",
      "((',', 'he'), 0.0010923655783468867)\n",
      "((',', 'like'), 0.0010923655783468867)\n",
      "((',', 'my'), 0.0010923655783468867)\n",
      "((',', 'or'), 0.0010923655783468867)\n",
      "((',', 'that'), 0.0010923655783468867)\n",
      "((',', 'they'), 0.0010923655783468867)\n",
      "(('and', 'he'), 0.0010923655783468867)\n",
      "(('day', ','), 0.0010923655783468867)\n",
      "(('when', 'the'), 0.0010923655783468867)\n",
      "((';', 'the'), 0.0009709916251972327)\n",
      "(('father', ','), 0.0009709916251972327)\n",
      "(('from', 'the'), 0.0009709916251972327)\n",
      "(('no', 'more'), 0.0009709916251972327)\n",
      "(('the', 'sun'), 0.0009709916251972327)\n",
      "((',', 'where'), 0.0008496176720475786)\n",
      "((',', 'with'), 0.0008496176720475786)\n",
      "(('a', 'little'), 0.0008496176720475786)\n",
      "(('all', 'the'), 0.0008496176720475786)\n"
     ]
    }
   ],
   "source": [
    "# scores are sorted in decreasing frequency\n",
    "for bscore in poemscored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('in', 'the'), 0.0055832018448840875)\n",
      "(('of', 'the'), 0.0033984706881903144)\n",
      "(('and', 'the'), 0.0032770967350406605)\n",
      "(('and', 'i'), 0.0021847311566937735)\n",
      "(('on', 'the'), 0.0016992353440951572)\n",
      "(('the', 'little'), 0.0016992353440951572)\n",
      "(('to', 'the'), 0.0016992353440951572)\n",
      "(('in', 'a'), 0.001577861390945503)\n",
      "(('i', 'am'), 0.001456487437795849)\n",
      "(('like', 'a'), 0.001456487437795849)\n",
      "(('the', 'human'), 0.001456487437795849)\n",
      "(('the', 'night'), 0.001213739531496541)\n",
      "(('and', 'he'), 0.0010923655783468867)\n",
      "(('when', 'the'), 0.0010923655783468867)\n",
      "(('from', 'the'), 0.0009709916251972327)\n",
      "(('no', 'more'), 0.0009709916251972327)\n",
      "(('the', 'sun'), 0.0009709916251972327)\n",
      "(('a', 'little'), 0.0008496176720475786)\n",
      "(('all', 'the'), 0.0008496176720475786)\n",
      "(('an', 'infant'), 0.0008496176720475786)\n",
      "(('hear', 'the'), 0.0008496176720475786)\n",
      "(('little', 'boy'), 0.0008496176720475786)\n",
      "(('little', 'lamb'), 0.0008496176720475786)\n",
      "(('my', 'mother'), 0.0008496176720475786)\n",
      "(('the', 'vales'), 0.0008496176720475786)\n",
      "(('where', 'the'), 0.0008496176720475786)\n",
      "(('and', 'love'), 0.0007282437188979245)\n",
      "(('and', 'not'), 0.0007282437188979245)\n",
      "(('but', 'i'), 0.0007282437188979245)\n",
      "(('can', 'it'), 0.0007282437188979245)\n",
      "(('can', 'not'), 0.0007282437188979245)\n",
      "(('i', 'see'), 0.0007282437188979245)\n",
      "(('i', 'was'), 0.0007282437188979245)\n",
      "(('in', 'every'), 0.0007282437188979245)\n",
      "(('so', 'i'), 0.0007282437188979245)\n",
      "(('songs', 'of'), 0.0007282437188979245)\n",
      "(('voice', 'of'), 0.0007282437188979245)\n",
      "(('while', 'the'), 0.0007282437188979245)\n",
      "(('with', 'the'), 0.0007282437188979245)\n",
      "(('among', 'the'), 0.0006068697657482705)\n",
      "(('and', 'all'), 0.0006068697657482705)\n",
      "(('and', 'we'), 0.0006068697657482705)\n",
      "(('because', 'i'), 0.0006068697657482705)\n",
      "(('can', 'i'), 0.0006068697657482705)\n",
      "(('filled', 'with'), 0.0006068697657482705)\n",
      "(('human', 'form'), 0.0006068697657482705)\n",
      "(('i', 'can'), 0.0006068697657482705)\n",
      "(('it', 'be'), 0.0006068697657482705)\n",
      "(('of', 'my'), 0.0006068697657482705)\n",
      "(('of', 'thel'), 0.0006068697657482705)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "poemfinder.apply_word_filter(alpha_filter)\n",
    "poemscored = poemfinder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in poemscored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('.', \"''\"), 0.002427479062993082)\n",
      "(('.', '``'), 0.0020633572035441195)\n",
      "(('lamb', ','), 0.001213739531496541)\n",
      "(('love', ','), 0.001213739531496541)\n",
      "(('night', ','), 0.001213739531496541)\n",
      "(('sleep', ','), 0.001213739531496541)\n",
      "(('!', \"''\"), 0.0010923655783468867)\n",
      "((',', 'like'), 0.0010923655783468867)\n",
      "(('day', ','), 0.0010923655783468867)\n",
      "(('father', ','), 0.0009709916251972327)\n",
      "(('delight', ','), 0.0008496176720475786)\n",
      "(('little', 'boy'), 0.0008496176720475786)\n",
      "(('little', 'lamb'), 0.0008496176720475786)\n",
      "(('peace', ','), 0.0008496176720475786)\n",
      "(('thee', '?'), 0.0008496176720475786)\n",
      "(('!', 'sweet'), 0.0007282437188979245)\n",
      "((',', 'till'), 0.0007282437188979245)\n",
      "((':', '``'), 0.0007282437188979245)\n",
      "(('?', '``'), 0.0007282437188979245)\n",
      "(('away', ','), 0.0007282437188979245)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "poemfinder.apply_word_filter(lambda w: w in stopwords)\n",
    "poemscored = poemfinder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in poemscored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.020997693894890156)\n",
      "(('in', 'the'), 0.0055832018448840875)\n",
      "(('.', 'the'), 0.0037625925476392767)\n",
      "(('of', 'the'), 0.0033984706881903144)\n",
      "(('and', 'the'), 0.0032770967350406605)\n",
      "((',', 'the'), 0.003155722781891006)\n",
      "(('.', \"''\"), 0.002427479062993082)\n",
      "(('.', 'and'), 0.0023061051098434275)\n",
      "(('and', 'i'), 0.0021847311566937735)\n",
      "(('.', '``'), 0.0020633572035441195)\n",
      "((';', 'and'), 0.0020633572035441195)\n",
      "((',', 'to'), 0.0019419832503944654)\n",
      "((',', 'but'), 0.0016992353440951572)\n",
      "(('on', 'the'), 0.0016992353440951572)\n",
      "(('the', 'little'), 0.0016992353440951572)\n",
      "(('to', 'the'), 0.0016992353440951572)\n",
      "((',', 'i'), 0.001577861390945503)\n",
      "((',', 'in'), 0.001577861390945503)\n",
      "(('in', 'a'), 0.001577861390945503)\n",
      "(('i', 'am'), 0.001456487437795849)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter (on a new finder) to remove low frequency words\n",
    "poemfinder2 = BigramCollocationFinder.from_words(poemwords)\n",
    "poemfinder2.apply_freq_filter(2)\n",
    "poemscored = poemfinder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in poemscored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('no', 'more'), 8.668403524211424)\n",
      "(('human', 'form'), 8.330181621983412)\n",
      "(('an', 'infant'), 7.423291026374892)\n",
      "(('little', 'boy'), 6.86432373418668)\n",
      "(('filled', 'with'), 6.700825001903802)\n",
      "(('little', 'lamb'), 6.416864757215459)\n",
      "(('smiles', 'on'), 6.411318384708817)\n",
      "(('because', 'i'), 5.985885714067594)\n",
      "(('it', 'be'), 5.828344437081116)\n",
      "(('can', 'it'), 5.7352350326896335)\n",
      "(('songs', 'of'), 5.596036546879585)\n",
      "(('i', 'am'), 5.570848214788752)\n",
      "(('my', 'mother'), 5.1926415043631415)\n",
      "(('can', 'not'), 5.166951273115108)\n",
      "(('i', 'see'), 4.570848214788752)\n",
      "(('like', 'a'), 4.475248324100075)\n",
      "(('voice', 'of'), 4.403391468937189)\n",
      "(('in', 'every'), 4.366201834168072)\n",
      "(('so', 'i'), 4.17853079200999)\n",
      "(('of', 'thel'), 4.140357063103394)\n",
      "(('the', 'vales'), 3.86760631817598)\n",
      "(('the', 'human'), 3.8151388982818464)\n",
      "(('the', 'sun'), 3.770744778923392)\n",
      "(('i', 'was'), 3.616651904401877)\n",
      "(('among', 'the'), 3.552104492448052)\n",
      "(('a', 'little'), 3.335070666051811)\n",
      "(('but', 'i'), 3.322920701345165)\n",
      "(('can', 'i'), 3.3078138089549576)\n",
      "(('i', 'can'), 3.3078138089549576)\n",
      "(('hear', 'the'), 3.0375313196182923)\n",
      "(('while', 'the'), 3.0077839762242427)\n",
      "(('and', 'we'), 2.799775284884344)\n",
      "(('the', 'weeping'), 2.7447495703904483)\n",
      "(('the', 'night'), 2.7447495703904465)\n",
      "(('till', 'the'), 2.6452138968395342)\n",
      "(('in', 'the'), 2.6141870012189106)\n",
      "(('when', 'the'), 2.592746476945397)\n",
      "(('in', 'a'), 2.5804572060661837)\n",
      "(('on', 'the'), 2.578099700980994)\n",
      "(('the', 'green'), 2.552104492448052)\n",
      "(('the', 'voice'), 2.552104492448052)\n",
      "(('the', 'little'), 2.5456782232886166)\n",
      "(('where', 'the'), 2.393675129843569)\n",
      "(('and', 'love'), 2.2922915368409047)\n",
      "(('from', 'the'), 2.2301763975606885)\n",
      "(('and', 'he'), 1.9278801106320262)\n",
      "(('of', 'the'), 1.8477067607382747)\n",
      "(('of', 'my'), 1.765317631756469)\n",
      "(('all', 'the'), 1.752129100756047)\n",
      "(('and', 'not'), 1.7240077772663795)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "poemfinder.apply_freq_filter(5)\n",
    "poemscored = poemfinder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in poemscored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for trigrams and trigram measures\n",
    "from nltk.collocations import *\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the trigram finder and score the trigrams by frequency\n",
    "poemtrifinder = TrigramCollocationFinder.from_words(poemwords)\n",
    "poemtriscored = poemtrifinder.score_ngrams(trigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and', 'the'), 0.0020633572035441195)\n",
      "((',', 'and', 'i'), 0.001213739531496541)\n",
      "((',', 'and', 'he'), 0.0008496176720475786)\n",
      "(('little', 'lamb', ','), 0.0008496176720475786)\n",
      "((',', 'like', 'a'), 0.0006068697657482705)\n",
      "((',', 'the', 'human'), 0.0006068697657482705)\n",
      "(('.', \"''\", 'the'), 0.0006068697657482705)\n",
      "(('.', 'the', 'little'), 0.0006068697657482705)\n",
      "(('can', 'it', 'be'), 0.0006068697657482705)\n",
      "(('the', 'human', 'form'), 0.0006068697657482705)\n",
      "(('the', 'voice', 'of'), 0.0006068697657482705)\n",
      "(('!', 'weep', '!'), 0.00048549581259861634)\n",
      "((',', 'and', 'her'), 0.00048549581259861634)\n",
      "((',', 'and', 'not'), 0.00048549581259861634)\n",
      "((',', 'in', 'the'), 0.00048549581259861634)\n",
      "((',', 'pity', ','), 0.00048549581259861634)\n",
      "(('.', '``', 'and'), 0.00048549581259861634)\n",
      "(('?', 'what', 'the'), 0.00048549581259861634)\n",
      "(('and', 'love', ','), 0.00048549581259861634)\n",
      "(('it', 'be', '!'), 0.00048549581259861634)\n",
      "(('mercy', ',', 'pity'), 0.00048549581259861634)\n",
      "(('never', 'can', 'it'), 0.00048549581259861634)\n",
      "(('of', 'the', 'night'), 0.00048549581259861634)\n",
      "(('of', 'the', 'vales'), 0.00048549581259861634)\n",
      "(('peace', ',', 'and'), 0.00048549581259861634)\n",
      "(('pity', ',', 'peace'), 0.00048549581259861634)\n",
      "(('the', 'little', 'boy'), 0.00048549581259861634)\n",
      "(('the', 'vales', 'of'), 0.00048549581259861634)\n",
      "(('vales', 'of', 'har'), 0.00048549581259861634)\n",
      "(('weep', '!', 'weep'), 0.00048549581259861634)\n"
     ]
    }
   ],
   "source": [
    "# scores are sorted in decreasing frequency\n",
    "for tscore in poemtriscored[:30]:\n",
    "    print (tscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('can', 'it', 'be'), 0.0006068697657482705)\n",
      "(('the', 'human', 'form'), 0.0006068697657482705)\n",
      "(('the', 'voice', 'of'), 0.0006068697657482705)\n",
      "(('never', 'can', 'it'), 0.00048549581259861634)\n",
      "(('of', 'the', 'night'), 0.00048549581259861634)\n",
      "(('of', 'the', 'vales'), 0.00048549581259861634)\n",
      "(('the', 'little', 'boy'), 0.00048549581259861634)\n",
      "(('the', 'vales', 'of'), 0.00048549581259861634)\n",
      "(('vales', 'of', 'har'), 0.00048549581259861634)\n",
      "(('an', 'infant', 'small'), 0.00036412185944896227)\n",
      "(('and', 'not', 'sit'), 0.00036412185944896227)\n",
      "(('book', 'of', 'thel'), 0.00036412185944896227)\n",
      "(('can', 'i', 'see'), 0.00036412185944896227)\n",
      "(('day', 'and', 'night'), 0.00036412185944896227)\n",
      "(('garden', 'of', 'love'), 0.00036412185944896227)\n",
      "(('heard', 'on', 'the'), 0.00036412185944896227)\n",
      "(('human', 'form', 'divine'), 0.00036412185944896227)\n",
      "(('i', 'went', 'to'), 0.00036412185944896227)\n",
      "(('in', 'the', 'year'), 0.00036412185944896227)\n",
      "(('little', 'boy', 'lost'), 0.00036412185944896227)\n",
      "(('o', 'little', 'cloud'), 0.00036412185944896227)\n",
      "(('on', 'the', 'green'), 0.00036412185944896227)\n",
      "(('pretty', 'rose', 'tree'), 0.00036412185944896227)\n",
      "(('seen', 'on', 'the'), 0.00036412185944896227)\n",
      "(('songs', 'of', 'innocence'), 0.00036412185944896227)\n",
      "(('the', 'book', 'of'), 0.00036412185944896227)\n",
      "(('the', 'echoing', 'green'), 0.00036412185944896227)\n",
      "(('the', 'garden', 'of'), 0.00036412185944896227)\n",
      "(('the', 'human', 'dress'), 0.00036412185944896227)\n",
      "(('the', 'little', 'ones'), 0.00036412185944896227)\n",
      "(('the', 'sun', 'does'), 0.00036412185944896227)\n",
      "(('thel', 'is', 'like'), 0.00036412185944896227)\n",
      "(('to', 'welcome', 'in'), 0.00036412185944896227)\n",
      "(('welcome', 'in', 'the'), 0.00036412185944896227)\n",
      "(('who', 'made', 'thee'), 0.00036412185944896227)\n",
      "((\"'d\", 'her', 'pitying'), 0.00024274790629930817)\n",
      "((\"'ll\", 'tell', 'thee'), 0.00024274790629930817)\n",
      "((\"'s\", 'song', 'when'), 0.00024274790629930817)\n",
      "(('a', 'divine', 'image'), 0.00024274790629930817)\n",
      "(('a', 'happy', 'blossom'), 0.00024274790629930817)\n",
      "(('a', 'human', 'face'), 0.00024274790629930817)\n",
      "(('a', 'human', 'heart'), 0.00024274790629930817)\n",
      "(('a', 'land', 'of'), 0.00024274790629930817)\n",
      "(('a', 'shade', \"o'er\"), 0.00024274790629930817)\n",
      "(('a', 'summer', 'morn'), 0.00024274790629930817)\n",
      "(('all', 'the', 'livelong'), 0.00024274790629930817)\n",
      "(('and', 'builds', 'a'), 0.00024274790629930817)\n",
      "(('and', 'gives', 'his'), 0.00024274790629930817)\n",
      "(('and', 'i', 'am'), 0.00024274790629930817)\n",
      "(('and', 'i', 'can'), 0.00024274790629930817)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "poemtrifinder.apply_word_filter(alpha_filter)\n",
    "poemtriscored = poemtrifinder.score_ngrams(trigram_measures.raw_freq)\n",
    "for tscore in poemtriscored[:50]:\n",
    "    print (tscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('can', 'it', 'be'), 13.836597964177166)\n",
      "(('the', 'human', 'form'), 12.560358019544102)\n",
      "(('the', 'voice', 'of'), 8.370533460664085)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "poemtrifinder.apply_freq_filter(5)\n",
    "poemtriscored = poemtrifinder.score_ngrams(trigram_measures.pmi)\n",
    "for tscore in poemtriscored[:50]:\n",
    "    print (tscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: CITY CHICKEN by D . M . Hanna...>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second document\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpus_root = 'C:/Users/HP/Desktop/Grad/IST 664 Natural Language Processing/HW'\n",
    "file = \"chik.txt\"\n",
    "wordlists = PlaintextCorpusReader(corpus_root, file)\n",
    "corpus = nltk.Text(wordlists.words())\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30184\n",
      "['`', 'anyone', 'who', 'has', 'not', 'worked', 'for', 'them', 'simply', 'can', 'not', 'understand', 'them', '.', \"'\", '-', 'mille', 'vennamun', ',', 'introduction', 'to', ':', '`', 'the', 'use', 'of', 'ashes', ':', 'bureau', 'of', 'procuration', \"manual'\", 'half', 'past', 'eight', '.', 'the', 'bedside', 'alarm', 'woke', 'kelanie', 'up', 'with', 'the', 'sampled', 'victory-screech', 'of', 'some', 'carnivorous', 'xenoform', '.', 'she', 'was', 'up', 'immediately', ',', 'eyes', 'wide', ',', 'fingers', 'clawing', 'the', 'pillow-pads', ',', 'gasping', 'with', 'shock', 'as', 'the', 'subconsciously-induced', 'adrenalin', 'shivered', 'through', 'her', 'system', '.', 'as', 'she', 'calmed', 'down', ',', 'her', 'pupils', 'dilated', 'out', 'from', 'crisis-', 'induced', 'pinpricks', ',', 'her', 'breathing', 'and', 'pulse', 'rates', 'returned', 'to', 'normal', ',', 'and', 'she', 'wondered', ',', 'not', 'for', 'the', 'first', 'or', 'last', 'time']\n"
     ]
    }
   ],
   "source": [
    "f=open('bureau.txt','rU')\n",
    "raw=f.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "mywords = [w.lower( ) for w in tokens] \n",
    "# show some of the words\n",
    "print(len(mywords))\n",
    "print(mywords[ :110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['`', 'anyone', 'who', 'has', 'not', 'worked', 'for', 'them', 'simply', 'can', 'not', 'understand', 'them', '.', \"'\", '-', 'mille', 'vennamun', ',', 'introduction', 'to', ':', '`', 'the', 'use', 'of', 'ashes', ':', 'bureau', 'of', 'procuration', \"manual'\", 'half', 'past', 'eight', '.', 'the', 'bedside', 'alarm', 'woke', 'kelanie', 'up', 'with', 'the', 'sampled', 'victory-screech', 'of', 'some', 'carnivorous', 'xenoform', '.', 'she', 'was', 'up', 'immediately', ',', 'eyes', 'wide', ',', 'fingers', 'clawing', 'the', 'pillow-pads', ',', 'gasping', 'with', 'shock', 'as', 'the', 'subconsciously-induced', 'adrenalin', 'shivered', 'through', 'her', 'system', '.', 'as', 'she', 'calmed', 'down', ',', 'her', 'pupils', 'dilated', 'out', 'from', 'crisis-', 'induced', 'pinpricks', ',', 'her', 'breathing', 'and', 'pulse', 'rates', 'returned', 'to', 'normal', ',', 'and']\n",
      "['a', 'dick', ',', 'that', \"'s\", 'all', '!', \"'\", 'kelanie', 'replied', 'sarcastically', '.', 'robyn', 'held', 'up', 'a', 'hand', ',', 'palm', 'out', '.', 'it', 'appeared', 'as', 'a', 'mass', 'of', 'pale', 'pink', 'squares', 'on', 'the', 'display', 'projected', 'by', \"kelanie's\", 'notepad', '.', '`', 'i', 'know', ',', 'i', 'know', '...', 'this', 'was', 'dumped', 'in', 'my', 'lap', ',', 'and', 'i', 'do', \"n't\", 'know', 'any', 'more', 'about', 'it', 'than', 'you', ',', 'although', 'we', \"'re\", 'laying', 'even', 'money', 'that', 'it', 'has', 'something', 'to', 'do', 'with', 'the', 'humanist', 'faction', 'in', 'the', 'maracites-', \"'\", 'robyn', 'stopped', 'when', 'she', 'saw', 'the', '``', 'i', 'do', \"n't\", 'want', 'to', 'get', 'drawn', 'into', 'another', 'tedious', 'political', 'argument', \"''\", 'expression', 'on', 'kelanie', \"'s\", 'face', '.', '`', '-', 'and', '...', 'well', ',', 'at', 'the', 'base', 'level', ',', 'it', \"'s\", 'to', 'seal', 'a', 'trade', 'agreement', 'with', 'the', 'tendeysharhi', '.', 'what', 'else', 'can', 'i', 'say', '?', \"'\", '`', 'you', 'could', 'tell', 'me', 'something', 'about', 'millimillenary', ',', 'for', 'a', 'start', '...', 'have', 'you', 'ever', 'been', 'there', '?', \"'\", 'kely', 'thought', 'she', 'detected', 'a', 'smile', 'on', 'robyn', \"'s\", 'face', '.', '`', 'once', '.', 'there', 'are', 'other', 'humans', 'there', ',', 'i', 'believe', '.', 'and', 'despite', 'what', 'you', \"'ve\", 'undoubtedly', 'heard', 'of', 'the', \"nosan'no'os\", ',', 'you', 'wo', \"n't\", 'be', 'treated', 'like', 'a', 'sardine', 'in', 'a', 'tin', '.', 'their', 'ships', 'are', 'often', 'nearly', 'empty', ',', 'when', 'heading', 'back', 'towards', 'the', 'centre', '.', \"'\", 'kelanie', 'tilted', 'her', 'head', 'to', 'one', 'side', ',', 'staring', 'at', 'the', 'surrealist', 'image', 'that', 'her', 'notepad', 'was', 'showing', '.', '`', 'robyn', '...', 'what', 'do', 'you', 'think', 'about', 'the', \"nosan'no'os\", '?', \"'\", 'this', 'time', ',', 'she', 'was', 'sure', 'that', 'robyn', 'smiled', ',', 'before', 'giving', 'the', 'bureau', 'salute', '(', 'pressing', 'the', 'back', 'of', 'her', 'hand', 'to', 'her', 'lips', ')', 'and', 'hanging', 'up', '.', '*', '*', '*', '*', '*', '<', '000077', '>', 'requesting', 'connection', '...', '...', '...', '...', 'connection', 'established', 'connection', 'established', 'what', 'do', 'you', 'want', ',', '000077', '?', \"i'm\", 'very', 'busy', 'at', 'the', 'moment', '.', 'you', 'are', 'always', 'very', 'busy', '!', 'we', 'have', 'to', 'query', 'this', 'expenditure', '.', 'which', 'one', '?', 'authorisation', ':', '492497a9', ',', 'code', 'af1cf3c7f8c65e98a06ed63c87e542c', 'ahh', 'yes', '.', '(', 'miscellaneous', ')', ',', 'relating', 'to', 'the', 'termination', 'of', 'n-frf-knh/k', '.', 'what', 'seems', 'to', 'be', 'the', 'problem', '?', 'is', \"n't\", '5x10', 'to', 'the', 'minus', 'two', 'cci', 'rather', 'a', 'lot', 'to', 'devote', 'to', 'the', 'elimination', 'of', 'one', 'race', '?', 'it', 'is', 'indeed', '.', 'i', 'think', \"it's\", 'justified', ',', 'though', '.', 'well', ',', 'okay', ',', 'sure', ',', 'but', 'can', 'you', 'give', 'us', 'some', 'explanation', '?', 'this', '(', 'sigh', ')', 'is', 'going', 'to', 'throw', 'out', 'our', 'quarterly', 'budget', 'something', 'your', 'place', 'is', 'to', 'accept', 'orders', 'shocking', '.', 'and', 'execute', 'them', '.', 'my', 'place', 'is', 'to', 'formulate', 'orders', '.', 'that', 'is', 'all', 'the', 'explanation', 'i', 'need', 'to', 'understood', '...', 'give', '.', 'to', 'you', ',', 'particularly', '.', 'understood', ',', 'but', '-', '(', 'pause', ')', 'would', 'you', 'be', 'interested', 'in', '(', 'viewing', ')', 'my', 'simulations', 'and', 'projections', 'of', 'this', 'species', '?', 'if', 'you', 'have', 'four', '(', 'years', ')', 'to', 'spare', ',', 'you', 'might', 'find', 'them', 'illuminating', '.', 'besides', ',', 'what', '`', 'illuminating', \"'\", ',', 'ha', ',', 'ha', '!']\n"
     ]
    }
   ],
   "source": [
    "# check tokenization in poemwords\n",
    "print(mywords[:100])\n",
    "print(mywords[2000:2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 1676\n",
      "the \t 1671\n",
      ". \t 1307\n",
      "to \t 667\n",
      "of \t 635\n",
      "a \t 630\n",
      "and \t 522\n",
      "` \t 429\n",
      "' \t 420\n",
      "that \t 357\n",
      "her \t 345\n",
      "she \t 342\n",
      "in \t 339\n",
      "it \t 325\n",
      "was \t 257\n",
      "on \t 232\n",
      "you \t 220\n",
      "'s \t 193\n",
      "kelanie \t 189\n",
      "? \t 188\n",
      "we \t 187\n",
      "with \t 178\n",
      "as \t 174\n",
      "for \t 163\n",
      "; \t 157\n",
      "at \t 139\n",
      "this \t 135\n",
      "had \t 135\n",
      "i \t 133\n",
      "is \t 133\n",
      "marek \t 133\n",
      "they \t 132\n",
      "from \t 131\n",
      "n't \t 128\n",
      "have \t 123\n",
      "be \t 111\n",
      "- \t 110\n",
      "... \t 108\n",
      "are \t 104\n",
      "were \t 103\n",
      "by \t 100\n",
      "nosan'no'os \t 100\n",
      "up \t 99\n",
      ": \t 96\n",
      "tsiry-feylen \t 95\n",
      "one \t 94\n",
      "which \t 93\n",
      "there \t 93\n",
      "them \t 89\n",
      "into \t 86\n"
     ]
    }
   ],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist1 = FreqDist(mywords)\n",
    "# print the top 50 tokens by frequency\n",
    "nitems = ndist1.most_common(50)\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anyone', 'who', 'has', 'not', 'worked', 'for', 'them', 'simply', 'can', 'not', 'understand', 'them', 'mille', 'vennamun', 'introduction', 'to', 'the', 'use', 'of', 'ashes', 'bureau', 'of', 'procuration', \"manual'\", 'half', 'past', 'eight', 'the', 'bedside', 'alarm', 'woke', 'kelanie', 'up', 'with', 'the', 'sampled', 'victory-screech', 'of', 'some', 'carnivorous', 'xenoform', 'she', 'was', 'up', 'immediately', 'eyes', 'wide', 'fingers', 'clawing', 'the', 'pillow-pads', 'gasping', 'with', 'shock', 'as', 'the', 'subconsciously-induced', 'adrenalin', 'shivered', 'through', 'her', 'system', 'as', 'she', 'calmed', 'down', 'her', 'pupils', 'dilated', 'out', 'from', 'crisis-', 'induced', 'pinpricks', 'her', 'breathing', 'and', 'pulse', 'rates', 'returned', 'to', 'normal', 'and', 'she', 'wondered', 'not', 'for', 'the', 'first', 'or', 'last', 'time', 'if', 'life', 'was', 'like', 'this', 'in', 'the', 'private']\n",
      "25080\n"
     ]
    }
   ],
   "source": [
    "# apply the function to emmawords\n",
    "alphamywords = [w for w in mywords if not alpha_filter(w)]\n",
    "print(alphamywords[:100])\n",
    "print(len(alphamywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12706\n"
     ]
    }
   ],
   "source": [
    "stoppedmywords = [w for w in alphamywords if not w in stopwords]\n",
    "print(len(stoppedmywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('kelanie', 189)\n",
      "('marek', 133)\n",
      "(\"nosan'no'os\", 100)\n",
      "('tsiry-feylen', 95)\n",
      "('one', 94)\n",
      "('like', 71)\n",
      "('suit', 69)\n",
      "('back', 62)\n",
      "('said', 60)\n",
      "('two', 56)\n",
      "('ship', 49)\n",
      "('moridani', 46)\n",
      "('around', 43)\n",
      "('something', 40)\n",
      "('us', 40)\n",
      "('notepad', 36)\n",
      "('bythian', 36)\n",
      "('turned', 35)\n",
      "('three', 34)\n",
      "('going', 34)\n",
      "('think', 34)\n",
      "('earth', 33)\n",
      "('eyes', 31)\n",
      "('bythians', 31)\n",
      "('head', 30)\n",
      "('parkry', 29)\n",
      "('end', 29)\n",
      "('xeno', 28)\n",
      "('found', 27)\n",
      "('human', 27)\n",
      "('asteroid', 27)\n",
      "('still', 26)\n",
      "('behind', 25)\n",
      "('made', 25)\n",
      "('appeared', 25)\n",
      "('know', 25)\n",
      "('away', 25)\n",
      "('humans', 25)\n",
      "('wall', 24)\n",
      "('export', 24)\n",
      "('translator', 24)\n",
      "('even', 24)\n",
      "('get', 24)\n",
      "('front', 24)\n",
      "('first', 23)\n",
      "('time', 23)\n",
      "('control', 23)\n",
      "('side', 23)\n",
      "('way', 23)\n",
      "('replied', 22)\n"
     ]
    }
   ],
   "source": [
    "# use this list for a better frequency distribution\n",
    "mydist = FreqDist(stoppedmywords)\n",
    "myitems = mydist.most_common(50)\n",
    "for item in myitems:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['`', 'anyone', 'who', 'has', 'not', 'worked', 'for', 'them', 'simply', 'can', 'not', 'understand', 'them', '.', \"'\", '-', 'mille', 'vennamun', ',', 'introduction', 'to']\n",
      "[('`', 'anyone'), ('anyone', 'who'), ('who', 'has'), ('has', 'not'), ('not', 'worked'), ('worked', 'for'), ('for', 'them'), ('them', 'simply'), ('simply', 'can'), ('can', 'not'), ('not', 'understand'), ('understand', 'them'), ('them', '.'), ('.', \"'\"), (\"'\", '-'), ('-', 'mille'), ('mille', 'vennamun'), ('vennamun', ','), (',', 'introduction'), ('introduction', 'to')]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "mybigrams = list(nltk.bigrams(mywords))\n",
    "print(mywords[:21])\n",
    "print(mybigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(mywords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('.', \"'\"), 0.006592896899019348)\n",
      "(('.', '`'), 0.006592896899019348)\n",
      "(('of', 'the'), 0.006493506493506494)\n",
      "((',', 'and'), 0.0060959448714550755)\n",
      "(('.', 'she'), 0.004306917572223695)\n",
      "(('?', \"'\"), 0.003611184733633713)\n",
      "(('to', 'the'), 0.003611184733633713)\n",
      "(('.', 'the'), 0.0033130135170951498)\n",
      "(('in', 'the'), 0.003213623111582295)\n",
      "(('the', \"nosan'no'os\"), 0.002584150543334217)\n",
      "((',', '`'), 0.002451630002650411)\n",
      "(('on', 'the'), 0.0024184998674794595)\n",
      "((',', 'the'), 0.0023853697323085077)\n",
      "(('--', '--'), 0.002186588921282799)\n",
      "(('*', '*'), 0.0021203286509408957)\n",
      "((\"'\", 'kelanie'), 0.0019878081102570897)\n",
      "((\"'\", '`'), 0.001921547839915187)\n",
      "(('.', 'it'), 0.0018884177047442353)\n",
      "(('from', 'the'), 0.0017558971640604293)\n",
      "(('at', 'the'), 0.0016565067585475749)\n",
      "((\"'\", 'she'), 0.0015902464882056719)\n",
      "(('that', 'the'), 0.0014908560826928175)\n",
      "(('into', 'the'), 0.0014245958123509145)\n",
      "(('the', 'ship'), 0.0014245958123509145)\n",
      "((',', 'which'), 0.0013914656771799629)\n",
      "(('.', 'kelanie'), 0.0013914656771799629)\n",
      "(('.', 'we'), 0.0012920752716671085)\n",
      "(('to', 'be'), 0.0012258150013252055)\n",
      "((',', 'she'), 0.0011926848661542539)\n",
      "(('.', 'marek'), 0.0011264245958123508)\n"
     ]
    }
   ],
   "source": [
    "# scores are sorted in decreasing frequency\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.006493506493506494)\n",
      "(('to', 'the'), 0.003611184733633713)\n",
      "(('in', 'the'), 0.003213623111582295)\n",
      "(('the', \"nosan'no'os\"), 0.002584150543334217)\n",
      "(('on', 'the'), 0.0024184998674794595)\n",
      "(('from', 'the'), 0.0017558971640604293)\n",
      "(('at', 'the'), 0.0016565067585475749)\n",
      "(('that', 'the'), 0.0014908560826928175)\n",
      "(('into', 'the'), 0.0014245958123509145)\n",
      "(('the', 'ship'), 0.0014245958123509145)\n",
      "(('to', 'be'), 0.0012258150013252055)\n",
      "(('as', 'the'), 0.0011264245958123508)\n",
      "(('her', 'suit'), 0.0011264245958123508)\n",
      "(('we', 'have'), 0.0011264245958123508)\n",
      "(('with', 'a'), 0.0011264245958123508)\n",
      "(('it', 'was'), 0.0010932944606413995)\n",
      "(('do', \"n't\"), 0.0010601643254704478)\n",
      "(('for', 'a'), 0.0010601643254704478)\n",
      "(('in', 'a'), 0.0010601643254704478)\n",
      "(('of', 'a'), 0.0010601643254704478)\n",
      "(('and', 'then'), 0.0010270341902994964)\n",
      "(('kelanie', \"'s\"), 0.0009939040551285448)\n",
      "(('with', 'the'), 0.0009939040551285448)\n",
      "(('one', 'of'), 0.0009607739199575934)\n",
      "(('of', 'her'), 0.0009276437847866419)\n",
      "(('and', 'the'), 0.0008945136496156904)\n",
      "(('to', 'a'), 0.0008613835144447389)\n",
      "(('was', 'a'), 0.0008613835144447389)\n",
      "(('by', 'the'), 0.0008282533792737874)\n",
      "(('like', 'a'), 0.0008282533792737874)\n",
      "(('we', 'are'), 0.0008282533792737874)\n",
      "(('a', 'few'), 0.0007951232441028359)\n",
      "(('did', \"n't\"), 0.0007951232441028359)\n",
      "(('for', 'the'), 0.0007951232441028359)\n",
      "(('out', 'of'), 0.0007951232441028359)\n",
      "(('the', 'moridani'), 0.0007951232441028359)\n",
      "(('through', 'the'), 0.0007951232441028359)\n",
      "(('it', \"'s\"), 0.0007619931089318844)\n",
      "(('had', 'been'), 0.0007288629737609329)\n",
      "(('in', 'her'), 0.0007288629737609329)\n",
      "(('the', 'xeno'), 0.0007288629737609329)\n",
      "(('there', 'was'), 0.0007288629737609329)\n",
      "(('and', 'a'), 0.0006957328385899814)\n",
      "(('going', 'to'), 0.0006957328385899814)\n",
      "(('her', 'notepad'), 0.0006957328385899814)\n",
      "(('she', 'was'), 0.0006626027034190299)\n",
      "(('have', 'been'), 0.0006294725682480784)\n",
      "(('she', 'had'), 0.0006294725682480784)\n",
      "(('that', 'they'), 0.0006294725682480784)\n",
      "(('at', 'her'), 0.0005963424330771269)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('pthalklin', 'ervae'), 0.00043069175722236947)\n",
      "(('something', 'like'), 0.00036443148688046647)\n",
      "(('threat', 'termination'), 0.00036443148688046647)\n",
      "(('one', 'side'), 0.00023191094619666049)\n",
      "(('tsiry-feylen', 'said'), 0.00023191094619666049)\n",
      "(('carriage', 'return'), 0.00019878081102570898)\n",
      "(('data', 'service'), 0.00019878081102570898)\n",
      "(('kelanie', 'sat'), 0.00019878081102570898)\n",
      "(('line', 'feed'), 0.00019878081102570898)\n",
      "(('return', 'line'), 0.00019878081102570898)\n",
      "(('artificial', 'intelligence'), 0.00016565067585475748)\n",
      "(('asteroid', 'belt'), 0.00016565067585475748)\n",
      "(('bythian', 'scout'), 0.00016565067585475748)\n",
      "(('kelanie', 'felt'), 0.00016565067585475748)\n",
      "(('looked', 'like'), 0.00016565067585475748)\n",
      "(('miss', 'camden'), 0.00016565067585475748)\n",
      "((\"nosan'no'os\", 'export'), 0.00016565067585475748)\n",
      "((\"nosan'no'os\", 'transport'), 0.00016565067585475748)\n",
      "(('tickling', 'feeling'), 0.00016565067585475748)\n",
      "(('battle', 'suit'), 0.00013252054068380598)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('.', \"'\"), 0.006592896899019348)\n",
      "(('.', '`'), 0.006592896899019348)\n",
      "(('of', 'the'), 0.006493506493506494)\n",
      "((',', 'and'), 0.0060959448714550755)\n",
      "(('.', 'she'), 0.004306917572223695)\n",
      "(('?', \"'\"), 0.003611184733633713)\n",
      "(('to', 'the'), 0.003611184733633713)\n",
      "(('.', 'the'), 0.0033130135170951498)\n",
      "(('in', 'the'), 0.003213623111582295)\n",
      "(('the', \"nosan'no'os\"), 0.002584150543334217)\n",
      "((',', '`'), 0.002451630002650411)\n",
      "(('on', 'the'), 0.0024184998674794595)\n",
      "((',', 'the'), 0.0023853697323085077)\n",
      "(('--', '--'), 0.002186588921282799)\n",
      "(('*', '*'), 0.0021203286509408957)\n",
      "((\"'\", 'kelanie'), 0.0019878081102570897)\n",
      "((\"'\", '`'), 0.001921547839915187)\n",
      "(('.', 'it'), 0.0018884177047442353)\n",
      "(('from', 'the'), 0.0017558971640604293)\n",
      "(('at', 'the'), 0.0016565067585475749)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter (on a new finder) to remove low frequency words\n",
    "finder2 = BigramCollocationFinder.from_words(mywords)\n",
    "finder2.apply_freq_filter(2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.006493506493506494)\n",
      "(('to', 'the'), 0.003611184733633713)\n",
      "(('in', 'the'), 0.003213623111582295)\n",
      "(('the', \"nosan'no'os\"), 0.002584150543334217)\n",
      "(('on', 'the'), 0.0024184998674794595)\n",
      "(('--', '--'), 0.002186588921282799)\n",
      "(('from', 'the'), 0.0017558971640604293)\n",
      "(('at', 'the'), 0.0016565067585475749)\n",
      "(('that', 'the'), 0.0014908560826928175)\n",
      "(('into', 'the'), 0.0014245958123509145)\n",
      "(('the', 'ship'), 0.0014245958123509145)\n",
      "(('to', 'be'), 0.0012258150013252055)\n",
      "(('as', 'the'), 0.0011264245958123508)\n",
      "(('her', 'suit'), 0.0011264245958123508)\n",
      "(('we', 'have'), 0.0011264245958123508)\n",
      "(('with', 'a'), 0.0011264245958123508)\n",
      "(('it', 'was'), 0.0010932944606413995)\n",
      "(('do', \"n't\"), 0.0010601643254704478)\n",
      "(('for', 'a'), 0.0010601643254704478)\n",
      "(('in', 'a'), 0.0010601643254704478)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter on both words of the ngram\n",
    "finder2.apply_ngram_filter(lambda w1, w2: len(w1) < 2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"'phone\", 'pinged'), 14.881496384810111)\n",
      "(('+life', '28'), 14.881496384810111)\n",
      "(('-primary', 'diversion'), 14.881496384810111)\n",
      "(('19.5', 'km/sec'), 14.881496384810111)\n",
      "(('661528.', 'swine'), 14.881496384810111)\n",
      "(('9171', 'servers'), 14.881496384810111)\n",
      "(('9327685491767632151', 'interdepartmental'), 14.881496384810111)\n",
      "((']', '¥'), 14.881496384810111)\n",
      "(('^c', '/join'), 14.881496384810111)\n",
      "(('absurdist', 'organisation'), 14.881496384810111)\n",
      "(('accelerating', 'furiously'), 14.881496384810111)\n",
      "(('adrenalin', 'shivered'), 14.881496384810111)\n",
      "(('alexander', 'pope'), 14.881496384810111)\n",
      "(('already-gleaming', 'spoon'), 14.881496384810111)\n",
      "(('ambulatory', 'shrubs'), 14.881496384810111)\n",
      "(('ammunition', 'belts'), 14.881496384810111)\n",
      "(('ankles', 'hinted'), 14.881496384810111)\n",
      "(('annoying', 'off-shoots'), 14.881496384810111)\n",
      "(('anyhah-araha', 'eiyaha'), 14.881496384810111)\n",
      "((\"aouwwrr'lrr-\", 'interface-to-the-enemy'), 14.881496384810111)\n"
     ]
    }
   ],
   "source": [
    "### pointwise mutual information\n",
    "finder3 = BigramCollocationFinder.from_words(mywords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('carriage', 'return'), 12.296533884088955)\n",
      "(('artificial', 'intelligence'), 11.811107056918711)\n",
      "(('miss', 'camden'), 11.811107056918711)\n",
      "(('tickling', 'feeling'), 11.448536977534001)\n",
      "(('return', 'line'), 11.422064766172813)\n",
      "(('line', 'feed'), 11.199672344836365)\n",
      "(('pthalklin', 'ervae'), 10.974605789201593)\n",
      "(('threat', 'termination'), 10.434037407838886)\n",
      "(('data', 'service'), 10.3371758685863)\n",
      "(('asteroid', 'belt'), 9.6411820554764)\n",
      "(('bythian', 'scout'), 9.033499478255159)\n",
      "(('how', 'many'), 8.431463464175064)\n",
      "(('pick', 'up'), 8.252139764730499)\n",
      "(('ca', \"n't\"), 7.881496384810111)\n",
      "(('wo', \"n't\"), 7.881496384810109)\n",
      "(('i', \"'m\"), 7.8262139493089204)\n",
      "(('staring', 'at'), 7.762555312086603)\n",
      "(('went', 'over'), 7.552372788518541)\n",
      "(('some', 'sort'), 7.5029847615563785)\n",
      "(('held', 'up'), 7.444784842672895)\n",
      "(('at', 'least'), 7.440627217199239)\n",
      "(('filled', 'with'), 7.405762953843713)\n",
      "(('cut', 'off'), 7.396069557639867)\n",
      "(('person', 'at'), 7.384043688832872)\n",
      "(('followed', 'by'), 7.330749599426866)\n",
      "(('their', 'way'), 7.299040739699528)\n",
      "(('did', \"n't\"), 7.296533884088955)\n",
      "(('stared', 'at'), 7.277128484916359)\n",
      "(('could', 'see'), 7.213793453081017)\n",
      "(('looked', 'like'), 7.14678676458427)\n",
      "(('looking', 'for'), 7.085309253607809)\n",
      "(('should', 'be'), 6.98754484490909)\n",
      "(('has', 'been'), 6.924975021476989)\n",
      "(('glanced', 'at'), 6.888086194170462)\n",
      "(('more', 'than'), 6.886011865932602)\n",
      "(('something', 'like'), 6.869252789055361)\n",
      "(('fingers', 'into'), 6.777159724995373)\n",
      "((\"nosan'no'os\", 'transport'), 6.752213367865142)\n",
      "(('one', 'side'), 6.610700499133065)\n",
      "(('do', \"n't\"), 6.541646381925483)\n",
      "(('in', 'fact'), 6.476354921673767)\n",
      "(('we', \"'re\"), 6.4601328070063335)\n",
      "((\"'d\", 'like'), 6.409821170418066)\n",
      "(('it', 'seems'), 6.274166071060497)\n",
      "(('this', 'end'), 6.268627887519068)\n",
      "(('his', 'eyes'), 6.204834049952142)\n",
      "(('was', 'surprised'), 6.197799930503594)\n",
      "(('on', 'millimillenary'), 6.175518483127586)\n",
      "(('as', 'many'), 6.158444969768647)\n",
      "(('had', 'been'), 6.155587949618404)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "finder.apply_freq_filter(5)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the trigram finder and score the trigrams by frequency\n",
    "trifinder = TrigramCollocationFinder.from_words(mywords)\n",
    "triscored = trifinder.score_ngrams(trigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('--', '--', '--'), 0.0021203286509408957)\n",
      "(('*', '*', '*'), 0.0015902464882056719)\n",
      "(('.', \"'\", 'kelanie'), 0.0014245958123509145)\n",
      "((':', ':', ':'), 0.0008945136496156904)\n",
      "(('?', \"'\", '`'), 0.0008945136496156904)\n",
      "((',', 'and', 'then'), 0.0007951232441028359)\n",
      "(('.', \"'\", 'she'), 0.0007951232441028359)\n",
      "(('said', ',', '`'), 0.0007951232441028359)\n",
      "(('.', \"'\", '`'), 0.0007288629737609329)\n",
      "(('.', \"'\", 'the'), 0.0005963424330771269)\n",
      "(('.', '`', 'i'), 0.0005963424330771269)\n",
      "(('.', '`', 'we'), 0.0005963424330771269)\n",
      "(('.', 'there', 'was'), 0.0005300821627352239)\n",
      "(('of', 'the', \"nosan'no'os\"), 0.0005300821627352239)\n",
      "((',', 'and', 'the'), 0.0004969520275642724)\n",
      "(('.', \"'\", 'tsiry-feylen'), 0.0004969520275642724)\n",
      "(('out', 'of', 'the'), 0.0004969520275642724)\n",
      "(('there', 'was', 'a'), 0.0004969520275642724)\n",
      "(('<', '000077', '>'), 0.00046382189239332097)\n",
      "(('?', \"'\", 'tsiry-feylen'), 0.00046382189239332097)\n",
      "(('<', '997193', '>'), 0.00043069175722236947)\n",
      "(('for', 'a', 'moment'), 0.00043069175722236947)\n",
      "(('one', 'of', 'the'), 0.00043069175722236947)\n",
      "((',', 'and', 'she'), 0.00039756162205141797)\n",
      "(('?', \"'\", 'she'), 0.00039756162205141797)\n",
      "(('and', 'said', ','), 0.00039756162205141797)\n",
      "(('.', 'it', 'was'), 0.00036443148688046647)\n",
      "(('.', 'we', 'have'), 0.00036443148688046647)\n",
      "(('?', \"'\", 'the'), 0.00036443148688046647)\n",
      "(('appeared', 'to', 'be'), 0.00036443148688046647)\n"
     ]
    }
   ],
   "source": [
    "# scores are sorted in decreasing frequency\n",
    "for tscore in triscored[:30]:\n",
    "    print (tscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the', \"nosan'no'os\"), 0.0005300821627352239)\n",
      "(('out', 'of', 'the'), 0.0004969520275642724)\n",
      "(('there', 'was', 'a'), 0.0004969520275642724)\n",
      "(('for', 'a', 'moment'), 0.00043069175722236947)\n",
      "(('one', 'of', 'the'), 0.00043069175722236947)\n",
      "(('appeared', 'to', 'be'), 0.00036443148688046647)\n",
      "(('at', 'this', 'end'), 0.00033130135170951496)\n",
      "(('person', 'at', 'this'), 0.00033130135170951496)\n",
      "(('the', 'person', 'at'), 0.00033130135170951496)\n",
      "(('in', 'front', 'of'), 0.00029817121653856346)\n",
      "(('kelanie', \"'s\", 'notepad'), 0.00029817121653856346)\n",
      "(('that', 'the', \"nosan'no'os\"), 0.00029817121653856346)\n",
      "(('back', 'to', 'the'), 0.00026504108136761196)\n",
      "(('bureau', 'of', 'procuration'), 0.00026504108136761196)\n",
      "(('i', 'do', \"n't\"), 0.00026504108136761196)\n",
      "(('of', 'the', 'ship'), 0.00026504108136761196)\n",
      "(('over', 'to', 'the'), 0.00026504108136761196)\n",
      "(('the', 'pthalklin', 'ervae'), 0.00026504108136761196)\n",
      "(('the', 'ship', \"'s\"), 0.00026504108136761196)\n",
      "(('do', 'you', 'think'), 0.00023191094619666049)\n",
      "(('end', 'of', 'the'), 0.00023191094619666049)\n",
      "(('kelanie', 'and', 'marek'), 0.00023191094619666049)\n",
      "(('of', 'her', 'suit'), 0.00023191094619666049)\n",
      "(('carriage', 'return', 'line'), 0.00019878081102570898)\n",
      "(('front', 'of', 'the'), 0.00019878081102570898)\n",
      "(('of', 'the', 'moridani'), 0.00019878081102570898)\n",
      "(('on', 'the', 'screen'), 0.00019878081102570898)\n",
      "(('return', 'line', 'feed'), 0.00019878081102570898)\n",
      "(('side', 'of', 'the'), 0.00019878081102570898)\n",
      "(('the', 'side', 'of'), 0.00019878081102570898)\n",
      "(('to', 'be', 'a'), 0.00019878081102570898)\n",
      "(('was', 'about', 'to'), 0.00019878081102570898)\n",
      "(('we', 'do', \"n't\"), 0.00019878081102570898)\n",
      "(('what', \"'s\", 'going'), 0.00019878081102570898)\n",
      "((\"'s\", 'going', 'to'), 0.00016565067585475748)\n",
      "(('by', 'the', \"nosan'no'os\"), 0.00016565067585475748)\n",
      "(('edge', 'of', 'the'), 0.00016565067585475748)\n",
      "(('i', \"'d\", 'like'), 0.00016565067585475748)\n",
      "(('in', 'her', 'suit'), 0.00016565067585475748)\n",
      "(('in', 'the', \"nosan'no'os\"), 0.00016565067585475748)\n",
      "(('into', 'the', 'ship'), 0.00016565067585475748)\n",
      "(('of', 'kelanie', \"'s\"), 0.00016565067585475748)\n",
      "(('of', 'the', 'hatch'), 0.00016565067585475748)\n",
      "(('some', 'sort', 'of'), 0.00016565067585475748)\n",
      "(('something', 'like', 'a'), 0.00016565067585475748)\n",
      "(('the', 'front', 'of'), 0.00016565067585475748)\n",
      "(('to', 'one', 'side'), 0.00016565067585475748)\n",
      "(('to', 'the', 'control'), 0.00016565067585475748)\n",
      "(('to', 'the', 'ground'), 0.00016565067585475748)\n",
      "(('to', 'think', 'that'), 0.00016565067585475748)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "trifinder.apply_word_filter(alpha_filter)\n",
    "triscored = trifinder.score_ngrams(trigram_measures.raw_freq)\n",
    "for tscore in triscored[:50]:\n",
    "    print (tscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('carriage', 'return', 'line'), 23.718598650261768)\n",
      "(('return', 'line', 'feed'), 23.496206228925324)\n",
      "(('bureau', 'of', 'procuration'), 16.867417487239532)\n",
      "(('person', 'at', 'this'), 15.18872447659215)\n",
      "(('the', 'pthalklin', 'ervae'), 14.44916643780942)\n",
      "(('at', 'this', 'end'), 14.031183199605671)\n",
      "(('i', \"'d\", 'like'), 13.973000713893189)\n",
      "(('what', \"'s\", 'going'), 13.40124885112806)\n",
      "(('do', 'you', 'think'), 13.3616751340182)\n",
      "(('some', 'sort', 'of'), 13.07386836470696)\n",
      "(('kelanie', \"'s\", 'notepad'), 12.60829330813107)\n",
      "(('for', 'a', 'moment'), 12.423178892364199)\n",
      "(('appeared', 'to', 'be'), 12.4026093809481)\n",
      "(('i', 'do', \"n't\"), 12.367860331234404)\n",
      "(('what', 'do', 'you'), 11.696924607403396)\n",
      "(('to', 'one', 'side'), 11.625227105588344)\n",
      "(('the', 'person', 'at'), 11.55904405558179)\n",
      "(('we', 'do', \"n't\"), 11.46121080756912)\n",
      "(('something', 'like', 'a'), 11.314037631728254)\n",
      "(('up', 'the', 'ramp'), 11.04862850822569)\n",
      "(('you', 'do', \"n't\"), 10.963711148098295)\n",
      "(('in', 'front', 'of'), 10.632201025545506)\n",
      "((\"'s\", 'going', 'to'), 10.023458034804577)\n",
      "(('on', 'the', 'screen'), 9.876587661544104)\n",
      "(('there', 'was', 'a'), 9.825891986539542)\n",
      "(('into', 'the', 'ship'), 9.337450247629086)\n",
      "(('edge', 'of', 'the'), 9.260457142729258)\n",
      "(('in', 'her', 'suit'), 9.140802392927537)\n",
      "(('to', 'think', 'that'), 9.136134808043554)\n",
      "(('was', 'about', 'to'), 9.030050432400031)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "trifinder.apply_freq_filter(5)\n",
    "triscored = trifinder.score_ngrams(trigram_measures.pmi)\n",
    "for tscore in triscored[:30]:\n",
    "    print (tscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
